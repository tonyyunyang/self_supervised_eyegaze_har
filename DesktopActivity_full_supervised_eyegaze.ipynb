{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-19T14:01:59.000167Z",
     "start_time": "2024-06-19T14:01:58.996456Z"
    }
   },
   "source": [
    "# Ensure reproducibility\n",
    "import os\n",
    "print(os.environ.get(\"CUBLAS_WORKSPACE_CONFIG\")) # Default is None\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "print(os.environ.get(\"CUBLAS_WORKSPACE_CONFIG\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      ":4096:8\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.264708Z",
     "start_time": "2024-06-19T14:01:59.000841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import torch\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from pprint import pprint\n",
    "from utils.plant_seed import plant_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.optimizer import CosineScheduler\n",
    "from utils.dataset import FullySupervisedDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.dataset import extract_parameters_from_datatype\n",
    "from utils.load_model import load_create_classification_model\n",
    "from utils.load_data import get_fully_supervised_pretrain_indices\n",
    "from utils.train_model import train_fully_supervised_pretrain_model\n",
    "\n",
    "\n",
    "seed = 0\n",
    "seed_worker, g = plant_seed(seed)"
   ],
   "id": "73ff7a0f8a53b219",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.267841Z",
     "start_time": "2024-06-19T14:02:00.265347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "label_map = {\n",
    "    0: \"BROWSE\",\n",
    "    1: \"PLAY\",\n",
    "    2: \"READ\",\n",
    "    3: \"SEARCH\",\n",
    "    4: \"WATCH\",\n",
    "    5: \"WRITE\"\n",
    "}"
   ],
   "id": "cc8f35b133b6a22e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.280729Z",
     "start_time": "2024-06-19T14:02:00.268441Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config_file_path = \"utils/DesktopActivity_config.json\"\n",
    "with open(config_file_path, \"r\") as file:\n",
    "    config = json.load(file)\n",
    "pprint(config)"
   ],
   "id": "eb1dd6fd7f4e077",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'V1Conv': {'dilation': 1, 'kernel_size': 3, 'padding': 1, 'stride': 1},\n",
      " 'V2Conv': {'dilation': 1, 'kernel_size': 3, 'padding': 1, 'stride': 1},\n",
      " 'data_path': 'dataset/training_data/DesktopActivity_Standardized',\n",
      " 'data_type': 'overlap_0.0_window_10s',\n",
      " 'finetune_base_lr': 0.001,\n",
      " 'finetune_batch_size': 64,\n",
      " 'finetune_epoch': 100,\n",
      " 'finetune_final_lr': 0.0001,\n",
      " 'finetune_max_update_epochs': 100,\n",
      " 'finetune_proportion': 0.8,\n",
      " 'finetune_warmup_epochs': 10,\n",
      " 'kdd_model': {'conv_config': None,\n",
      "               'd_model': 128,\n",
      "               'dim_feedforward': 512,\n",
      "               'emb_dropout': 0.1,\n",
      "               'embedding': 'linear',\n",
      "               'enc_dropout': 0.1,\n",
      "               'feat_dim': 2,\n",
      "               'max_seq_len': None,\n",
      "               'n_heads': 8,\n",
      "               'n_layers': 6},\n",
      " 'label_smoothing': 0.1,\n",
      " 'pretrain_base_lr': 0.001,\n",
      " 'pretrain_batch_size': 64,\n",
      " 'pretrain_epoch': 100,\n",
      " 'pretrain_final_lr': 0.0001,\n",
      " 'pretrain_max_update_epochs': 100,\n",
      " 'pretrain_model_path': None,\n",
      " 'pretrain_proportion': 0.8,\n",
      " 'pretrain_warmup_epochs': 10,\n",
      " 'result_path': 'results/DesktopActivity'}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.285472Z",
     "start_time": "2024-06-19T14:02:00.281745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "overlap, window_seconds, window_length = extract_parameters_from_datatype(config['data_type'])\n",
    "print(f\"overlap {overlap}, window seconds: {window_seconds}, window length: {window_length}\")\n",
    "\n",
    "# assign the window length to the config\n",
    "config['kdd_model']['max_seq_len'] = window_length"
   ],
   "id": "72cf9527f6db50b9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlap 0.0, window seconds: 10, window length: 300\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.291685Z",
     "start_time": "2024-06-19T14:02:00.286006Z"
    }
   },
   "cell_type": "code",
   "source": [
    "subjects_dict_path = os.path.join(config['data_path'], config['data_type'], 'starting_indices.json')\n",
    "with open(subjects_dict_path, \"r\") as file:\n",
    "    subjects = json.load(file)\n",
    "pprint(subjects)\n",
    "\n",
    "data_file_path = os.path.join(config['data_path'], config['data_type'], f\"{config['data_type']}.h5\")\n",
    "with h5py.File(data_file_path, 'r') as h5_file:\n",
    "    last_index = h5_file['training_data'].shape[0] - 1\n",
    "    # print(last_index)"
   ],
   "id": "953c4affa3db1675",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P01': 0,\n",
      " 'P02': 179,\n",
      " 'P03': 359,\n",
      " 'P04': 539,\n",
      " 'P05': 719,\n",
      " 'P06': 899,\n",
      " 'P07': 1079,\n",
      " 'P08': 1259}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.544336Z",
     "start_time": "2024-06-19T14:02:00.292265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Pretrain Loop\n",
    "for leave_out_subject in subjects:\n",
    "    print(f\"Leave out subject: {leave_out_subject}\")\n",
    "    pretrain_test_indices, pretrain_train_indices = get_fully_supervised_pretrain_indices(subjects, leave_out_subject, last_index)\n",
    "    # split train indices into train and validation\n",
    "    pretrain_train_indices, pretrain_val_indices = train_test_split(pretrain_train_indices, test_size=config['pretrain_proportion'], random_state=seed)\n",
    "    \n",
    "    train_dataset = FullySupervisedDataset(data_file_path, pretrain_train_indices, label_map)\n",
    "    val_dataset = FullySupervisedDataset(data_file_path, pretrain_val_indices, label_map)\n",
    "    test_dataset = FullySupervisedDataset(data_file_path, pretrain_test_indices, label_map)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['pretrain_batch_size'], shuffle=True, num_workers=os.cpu_count(), worker_init_fn=seed_worker, generator=g) \n",
    "    val_loader = DataLoader(train_dataset, batch_size=config['pretrain_batch_size'], shuffle=False, num_workers=os.cpu_count(), worker_init_fn=seed_worker, generator=g) \n",
    "    test_loader = DataLoader(train_dataset, batch_size=config['pretrain_batch_size'], shuffle=False, num_workers=os.cpu_count(), worker_init_fn=seed_worker, generator=g)\n",
    "    \n",
    "    loaders = (train_loader, val_loader, test_loader)\n",
    "    \n",
    "    model, model_config = load_create_classification_model(config, num_classes=len(label_map))\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=config['label_smoothing'])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1.0, betas=(0.9, 0.999))\n",
    "    scheduler = CosineScheduler(max_update=config['pretrain_max_update_epochs'], base_lr=config['pretrain_base_lr'], final_lr=config['pretrain_final_lr'], warmup_steps=config['pretrain_warmup_epochs'], warmup_begin_lr=0.0)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=scheduler)\n",
    "    \n",
    "    tensorboard_writer = train_fully_supervised_pretrain_model(model, criterion, optimizer, scheduler, loaders, model_config, config, leave_out_subject)"
   ],
   "id": "9f06ff4baf389c8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave out subject: P01\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P01_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P02\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P02_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P03\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P03_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P04\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P04_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P05\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P05_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P06\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P06_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P07\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P07_leave_out/TensorBoard_Log then open http://localhost:6006\n",
      "Leave out subject: P08\n",
      "{'conv_config': None,\n",
      " 'd_model': 128,\n",
      " 'dim_feedforward': 512,\n",
      " 'emb_dropout': 0.1,\n",
      " 'embedding': 'linear',\n",
      " 'enc_dropout': 0.1,\n",
      " 'feat_dim': 2,\n",
      " 'max_len': 300,\n",
      " 'n_heads': 8,\n",
      " 'n_layers': 6,\n",
      " 'num_classes': 6}\n",
      "Number of classes: 6\n",
      "Linear embedding: 300 sequence length.\n",
      "=============================================================\n",
      "=====================Training via cuda===================\n",
      "=============================================================\n",
      "Run cmd: tensorboard --logdir=results/DesktopActivity/overlap_0.0_window_10s/feat_dim_2_d_model_128_n_heads_8_n_layers_6_d_ff_512_emb_dropout_0.1_enc_dropout_0.1_embedding_linear_conv_config_None/epochs_100_max_update_steps_100_warmup_steps_10_batch_size_64_base_lr_0.001_final_lr_0.0001_label_smoothing_0.1/P08_leave_out/TensorBoard_Log then open http://localhost:6006\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-19T14:02:00.546617Z",
     "start_time": "2024-06-19T14:02:00.544991Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "d1e0d374b29d74e0",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
